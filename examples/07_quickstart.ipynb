{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAlex Local - Quickstart Guide\n",
    "\n",
    "This notebook demonstrates the core features of `openalex-local`:\n",
    "\n",
    "1. **Search** - Full-text search across 459M+ scholarly works\n",
    "2. **Get** - Retrieve works by DOI or OpenAlex ID\n",
    "3. **Citations** - Generate APA and BibTeX citations\n",
    "4. **Cache** - Local caching for offline analysis\n",
    "5. **Async** - Concurrent search operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import openalex-local\n",
    "import openalex_local as oal\n",
    "from openalex_local import search, get, cache, aio, enrich_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Search\n",
    "\n",
    "Search across titles and abstracts using FTS5 syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple search\n",
    "results = search(\"machine learning neural networks\", limit=5)\n",
    "\n",
    "print(f\"Found {results.total:,} matches in {results.elapsed_ms:.1f}ms\\n\")\n",
    "\n",
    "for i, work in enumerate(results.works, 1):\n",
    "    print(f\"{i}. {work.title} ({work.year})\")\n",
    "    print(f\"   DOI: {work.doi or 'N/A'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get by DOI\n",
    "\n",
    "Retrieve a specific work with full metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get work by DOI\n",
    "work = get(\"10.7717/peerj.4375\")\n",
    "\n",
    "if work:\n",
    "    print(f\"Title: {work.title}\")\n",
    "    print(f\"Year: {work.year}\")\n",
    "    print(f\"Citations: {work.cited_by_count:,}\")\n",
    "    print(f\"Authors: {', '.join(work.authors[:3])}...\")\n",
    "    print(f\"\\nAbstract preview: {work.abstract[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Citations\n",
    "\n",
    "Generate formatted citations in APA or BibTeX style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APA citation\n",
    "print(\"APA Citation:\")\n",
    "print(work.citation(\"apa\"))\n",
    "print()\n",
    "\n",
    "# BibTeX entry\n",
    "print(\"BibTeX Entry:\")\n",
    "print(work.citation(\"bibtex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cache Workflow\n",
    "\n",
    "Create local caches for offline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cache from search\n",
    "if cache.exists(\"demo_cache\"):\n",
    "    cache.delete(\"demo_cache\")\n",
    "\n",
    "info = cache.create(\"demo_cache\", query=\"CRISPR\", limit=50)\n",
    "print(f\"Created cache with {info.count} papers\")\n",
    "\n",
    "# Get statistics\n",
    "stats = cache.stats(\"demo_cache\")\n",
    "print(f\"Year range: {stats['year_min']} - {stats['year_max']}\")\n",
    "print(f\"Mean citations: {stats['citations_mean']:.1f}\")\n",
    "\n",
    "# Query with filters\n",
    "recent = cache.query(\"demo_cache\", year_min=2020, limit=5)\n",
    "print(f\"\\nRecent papers (2020+): {len(recent)}\")\n",
    "\n",
    "# Cleanup\n",
    "cache.delete(\"demo_cache\")\n",
    "print(\"Cache deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Async Search\n",
    "\n",
    "Run concurrent searches for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def concurrent_search():\n",
    "    queries = [\"machine learning\", \"deep learning\", \"neural networks\"]\n",
    "    \n",
    "    # Run all searches concurrently\n",
    "    counts = await aio.count_many(queries)\n",
    "    \n",
    "    for query, count in counts.items():\n",
    "        print(f\"'{query}': {count:,} matches\")\n",
    "\n",
    "# Run async function\n",
    "await concurrent_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Enrich IDs\n",
    "\n",
    "Fetch full metadata for a list of IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich a list of IDs\n",
    "ids = [\"W2741809807\", \"10.1038/nature14539\"]\n",
    "works = enrich_ids(ids)\n",
    "\n",
    "for w in works:\n",
    "    print(f\"Title: {w.title}\")\n",
    "    print(f\"Year: {w.year}, Citations: {w.cited_by_count:,}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI Commands\n",
    "\n",
    "You can also use the CLI:\n",
    "\n",
    "```bash\n",
    "# Search\n",
    "openalex-local search \"machine learning\" -n 5\n",
    "\n",
    "# Get by DOI with citation\n",
    "openalex-local search-by-doi \"10.7717/peerj.4375\" --citation\n",
    "openalex-local search-by-doi \"10.7717/peerj.4375\" --bibtex\n",
    "\n",
    "# Cache commands\n",
    "openalex-local cache create mypapers -q \"CRISPR\" -l 100\n",
    "openalex-local cache stats mypapers\n",
    "openalex-local cache export mypapers refs.bib -f bibtex\n",
    "openalex-local cache delete mypapers --yes\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
